{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Requirements"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a43ea327c14e3a2e"
  },
  {
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import swifter\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T13:11:50.505093Z",
     "start_time": "2024-09-25T13:11:50.498679Z"
    }
   },
   "id": "18a54e084db38531",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'swifter'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mzipfile\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mswifter\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'swifter'"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Unzipping the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ba22b1621347e6b"
  },
  {
   "cell_type": "code",
   "source": [
    "with zipfile.ZipFile(\"Datasets/archive.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"Datasets\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T13:11:54.530091Z",
     "start_time": "2024-09-25T13:11:52.309319Z"
    }
   },
   "id": "94cd6bc1f14cf2f",
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Datasets\\\\Amazon-Products.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m zipfile\u001B[38;5;241m.\u001B[39mZipFile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasets/archive.zip\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m zip_ref:\n\u001B[1;32m----> 2\u001B[0m     \u001B[43mzip_ref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextractall\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDatasets\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1701\u001B[0m, in \u001B[0;36mZipFile.extractall\u001B[1;34m(self, path, members, pwd)\u001B[0m\n\u001B[0;32m   1698\u001B[0m     path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(path)\n\u001B[0;32m   1700\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m zipinfo \u001B[38;5;129;01min\u001B[39;00m members:\n\u001B[1;32m-> 1701\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extract_member\u001B[49m\u001B[43m(\u001B[49m\u001B[43mzipinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpwd\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\zipfile.py:1755\u001B[0m, in \u001B[0;36mZipFile._extract_member\u001B[1;34m(self, member, targetpath, pwd)\u001B[0m\n\u001B[0;32m   1751\u001B[0m         os\u001B[38;5;241m.\u001B[39mmkdir(targetpath)\n\u001B[0;32m   1752\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m targetpath\n\u001B[0;32m   1754\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopen(member, pwd\u001B[38;5;241m=\u001B[39mpwd) \u001B[38;5;28;01mas\u001B[39;00m source, \\\n\u001B[1;32m-> 1755\u001B[0m      \u001B[38;5;28mopen\u001B[39m(targetpath, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m target:\n\u001B[0;32m   1756\u001B[0m     shutil\u001B[38;5;241m.\u001B[39mcopyfileobj(source, target)\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m targetpath\n",
      "\u001B[1;31mPermissionError\u001B[0m: [Errno 13] Permission denied: 'Datasets\\\\Amazon-Products.csv'"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading the csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9125706d86594f1f"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accessories', \"men's shoes\", 'car & motorbike', 'music', 'pet supplies', \"kids' fashion\", 'industrial supplies', \"women's clothing\", 'home, kitchen, pets', 'beauty & health', 'grocery & gourmet foods', \"men's clothing\", 'sports & fitness', 'toys & baby products', 'tv, audio & cameras', 'home & kitchen', 'stores', 'bags & luggage', \"women's shoes\", 'appliances'}\n"
     ]
    }
   ],
   "source": [
    "#go over Amazon-Products.csv and check all main_categories\n",
    "main_categories = set()\n",
    "df = pd.read_csv(\"Datasets/Amazon-Products.csv\")\n",
    "for index, row in df.iterrows():\n",
    "    main_categories.add(row[\"main_category\"])\n",
    "print(main_categories)\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "path = os.getcwd() + \"/Datasets\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "csv_dfs = {}\n",
    "for f in csv_files:\n",
    "    file_name = f.split(\"\\\\\")[-1]\n",
    "    \n",
    "    # remove the .csv extension\n",
    "    file_name = file_name[:-4]\n",
    "    \n",
    "    if file_name == \"Amazon-Products\":\n",
    "        continue\n",
    "    \n",
    "    # read the csv file \n",
    "    df = pd.read_csv(f)\n",
    "    csv_dfs[file_name] = df\n",
    "    \n",
    "df_all = pd.read_csv(\"Datasets/Amazon-Products.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Usage"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ccce3e2eb6033cc"
  },
  {
   "cell_type": "code",
   "source": [
    "display(csv_dfs[\"Amazon Fashion\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T13:12:05.572028Z",
     "start_time": "2024-09-25T13:12:05.557707Z"
    }
   },
   "id": "c58a4a6de7b75851",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee4cbeef3047cb3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Amazon Fashion"
   ],
   "id": "7f7853ea851fd2a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:03:14.138847Z",
     "start_time": "2024-07-21T15:03:13.023847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "amazon_fashion_df = csv_dfs[\"Amazon Fashion\"]\n",
    "# drop rows with missing values  # TODO: can discount be Nan?\n",
    "amazon_fashion_df = amazon_fashion_df.dropna()\n",
    "# drop duplicates\n",
    "amazon_fashion_df = amazon_fashion_df.drop_duplicates()\n",
    "# drop rows with links that are not amazon links  # TODO: check if this is necessary\n",
    "amazon_fashion_df = amazon_fashion_df[amazon_fashion_df[\"link\"].str.contains(\"amazon.com\")]\n",
    "# drop rows with links that don't work  # FIXME: how?\n",
    "amazon_fashion_df = amazon_fashion_df[amazon_fashion_df[\"link\"].str.contains(\"404\")]\n",
    "# drop columns that are not needed\n",
    "amazon_fashion_df = amazon_fashion_df.drop(columns=[\"main_category\"])\n",
    "# normalize the ratings column\n",
    "amazon_fashion_df[\"rating\"] = amazon_fashion_df[\"rating\"] / 5.0"
   ],
   "id": "ad4ad41bde65dc11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Visualizing the data\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "6c3f16463776459e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T13:12:37.567431Z",
     "start_time": "2024-09-25T13:12:37.562431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def valid_link(link):\n",
    "    from faker import Faker\n",
    "    import requests\n",
    "    page = requests.get(link)\n",
    "    return page.status_code == 200\n",
    "\n",
    "\n",
    "def increment_link_count(num_links, subject, link):\n",
    "    if valid_link(link):\n",
    "        num_links[subject] += 1"
   ],
   "id": "3eb1e54d35027b2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T13:16:35.299657Z",
     "start_time": "2024-09-25T13:13:06.211407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "subjects = df_all[\"main_category\"].unique()\n",
    "num_links = {subject : 0 for subject in subjects}\n",
    "\n",
    "df_all.progress_apply(lambda x: increment_link_count(num_links, x[\"main_category\"], x[\"link\"]), axis=1)"
   ],
   "id": "a437480ee8258487",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen, build_opener\n",
    "# number of products plot\n",
    "plot = plt.figure()\n",
    "plot.set_figwidth(25)\n",
    "plot.set_figheight(25)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "for key in csv_dfs:\n",
    "    number_of_products = len(csv_dfs[key])\n",
    "    plt.bar(key, number_of_products, label=key)\n",
    "plt.xlabel('Category', fontsize=20)\n",
    "plt.ylabel('Number of products', fontsize=20)\n",
    "plt.title('Number of products in each category', fontsize=20)\n",
    "#make the text bigger for title\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#now plot the normalized number of broken links by the number of products\n",
    "plot_links_normalized = plt.figure()\n",
    "plot_links_normalized.set_figwidth(60)\n",
    "plot_links_normalized.set_figheight(25)\n",
    "plt.xticks(rotation=90)\n",
    "#make the text bigger for the labels\n",
    "plt.tick_params(axis='x', which='major', labelsize=30)\n",
    "plt.tick_params(axis='y', which='major', labelsize=20)\n",
    "\n",
    "\n",
    "#more space between the labels and the plot\n",
    "plt.subplots_adjust(left=0.1, right=0.7, top=0.7, bottom=0.1)\n",
    "#make the gap between each two bars bigger\n",
    "#pad between each label and the plot\n",
    "normalized_broken_links_arr=[]\n",
    "#go over all main_categories csvs and check the number of broken links\n",
    "for key in main_categories:\n",
    "    number_of_products_for_key = len(df_all[df_all[\"main_category\"] == key])\n",
    "    #check the number of broken links\n",
    "    num_broken_links = 0\n",
    "    for index, row in df_all[df_all[\"main_category\"] == key].iterrows():\n",
    "        #check if 404 in sstr\n",
    "        if \"404\" in row[\"link\"]:\n",
    "            num_broken_links += 1\n",
    "    #normalize the number of broken links by the number of products\n",
    "    normalized_broken_links = num_broken_links / number_of_products_for_key\n",
    "    normalized_broken_links_arr.append(normalized_broken_links)\n",
    "\n",
    "#sort\n",
    "normalized_broken_links_arr, main_categories = zip(*sorted(zip(normalized_broken_links_arr, main_categories), reverse=True))\n",
    "for i in range(len(main_categories)):\n",
    "    plt.bar(main_categories[i], normalized_broken_links_arr[i], label=main_categories[i])\n",
    "\n",
    "\n",
    "#sort bars from the highest to the lowest\n",
    "\n",
    "plt.xlabel('Category', fontsize=40)\n",
    "plt.ylabel('% of broken links', fontsize=40)\n",
    "plt.title('% of broken links in each category', fontsize=50)\n",
    "plt.subplots_adjust(wspace=48)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "id": "d8e1a39ae6abdd80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reality Check"
   ],
   "id": "4ac104ecdab78eac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import text_evaluation\n",
    "import imager.vgg.VGG\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "url1 = 'https://www.amazon.com/Under-Armour-Charged-Assert-X-Wide/dp/B08CFT75X3/ref=sr_1_2?_encoding=UTF8&content-id=amzn1.sym.56e14e61-447a-443b-9528-4b285fddeeac&crid=1QEZIUFPCL3YZ&dib=eyJ2IjoiMSJ9.ft2_UOW6_812lc9l1-QSVp262n9lnrp9JkYxbzch50YDBc3lzBNyzMAiBk-I0IdyUcrfaGVjLJRshNC2heUyGwkRM8s0DoTb4M6iESi81wnkVgmzqAjgcRlkbEfcDI24cTaNoVMc3Mdool0oekYx_66W7cs9xa5ygzH_QQjvrB0aNX-Mz-IKmLBuA6CGzSxzDgw_WbXkr6Xhdj7AwUuSIj9YhQVnyp4PvUZ3YtcB7qdUQcQHrIv325on_XbSy7GY5SU2aZGHOTLcpAiBLoyJGZCQLeNUz3abwIVYKtMoNGI.ThotIlFS47Lro8cttfDqEFWQr5sueLmTYX1UdYgp-yg&dib_tag=se&keywords=Shoes&pd_rd_r=20072d94-7d9c-4817-9c8a-c541f1ee3e84&pd_rd_w=iiWNK&pd_rd_wg=UgsLQ&pf_rd_p=56e14e61-447a-443b-9528-4b285fddeeac&pf_rd_r=C7WVXH61VXFF81AV2G2Y&qid=1720343515&refinements=p_36%3A-5000&rnid=2661611011&sprefix=shoes%2Caps%2C145&sr=8-2&th=1'\n",
    "\n",
    "url2='https://www.amazon.com/dp/B0BZXMXTT2/ref=sspa_dk_detail_1?psc=1&pf_rd_p=386c274b-4bfe-4421-9052-a1a56db557ab&pf_rd_r=FND5XJ34Y17881CR2G9D&pd_rd_wg=Yvcge&pd_rd_w=cexMT&content-id=amzn1.sym.386c274b-4bfe-4421-9052-a1a56db557ab&pd_rd_r=c790c2c3-81de-4a2c-b1a0-9b79447aab15&s=shoes&sp_csd=d2lkZ2V0TmFtZT1zcF9kZXRhaWxfdGhlbWF0aWM'\n",
    "\n",
    "url3='https://www.amazon.com/LEGO-Disney-Stitch-Building-Buildable/dp/B0CGY26D8G/ref=sr_1_2?crid=23QXV07HHVE7M&dib=eyJ2IjoiMSJ9.L1iHMZSfL_eRoYJJ69o-g2IWQlmfgJkyM2LBjhLKlvsmkzIA9Zh2e4QSKHALLuqwy1d2M_ESlzhsDcpjIh7pq_CZrm5-Zb2agU1r-sZNGxEioi8YWdvV2hBLeNCAjXJ2y91k2g08MsLNkkRiJoKTQkElGXyay7_2d-qJFGOyIz2l5lJ_QgkjW-B_i0HbcYyeOjhVguf03Rgkps7ORX4S_CXTnHCTCJHwEp__yG9gxVoNmi5M7F0I6WmVvgcswDWOD5VcZOwIuM6bgp2Wo9QO9rABEvAfiqxWOgJL7hJpTkk.7Z34_veo1afRteTuAz4oI6qG5RDHZKAyH0EXoDFmrHU&dib_tag=se&keywords=lego&qid=1721051615&sprefix=lego%2B%2Caps%2C222&sr=8-2&th=1'\n",
    "\n",
    "#get similarity_score(url1, url2) and similarity_score(url1, url3)\n",
    "similarity_score1 = text_evaluation.similarity_score(url1, url2)\n",
    "similarity_score2 = text_evaluation.similarity_score(url1, url3)\n",
    "print(\"Similarity score between url1 and url2: \", similarity_score1)\n",
    "print(\"Similarity score between url1 and url3: \", similarity_score2)\n",
    "#take images from reality check between vgg and description directory and compare them with vgg\n",
    "img1 = \"\\\\underarmor1.jpg\"\n",
    "img2 = \"\\\\underarmor2.jpg\"\n",
    "img3 = \"\\\\lego.jpg\"\n",
    "#load image\n",
    "path_to_images = os.getcwd() + \"\\\\reality_check\"\n",
    "img1= imager.vgg.VGG.load_image(path_to_images + img1)\n",
    "img2= imager.vgg.VGG.load_image(path_to_images + img2)\n",
    "img3= imager.vgg.VGG.load_image(path_to_images + img3)\n",
    "\n",
    "\n",
    "#get image embeddings by vgg\n",
    "vgg1 = imager.vgg.VGG.get_image_embeddings(img1)\n",
    "vgg2 = imager.vgg.VGG.get_image_embeddings(img2)\n",
    "vgg3 = imager.vgg.VGG.get_image_embeddings(img3)\n",
    "#compare the embeddings\n",
    "similarity_score3 = imager.vgg.VGG.get_score(vgg1, vgg2)\n",
    "similarity_score4 = imager.vgg.VGG.get_score(vgg1, vgg3)\n",
    "print(\"Similarity score between img1 and img2: \", similarity_score3)\n",
    "print(\"Similarity score between img1 and img3: \", similarity_score4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d46f8dc3e5feaf8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import text_evaluation\n",
    "img1 = \"\\\\underarmor1.jpg\"\n",
    "img2 = \"\\\\underarmor2.jpg\"\n",
    "img3 = \"\\\\lego.jpg\"\n",
    "#load image\n",
    "path_to_images = os.getcwd() + \"\\\\reality_check\"\n",
    "img1= imager.vgg.VGG.load_image(path_to_images + img1)\n",
    "img2= imager.vgg.VGG.load_image(path_to_images + img2)\n",
    "img3= imager.vgg.VGG.load_image(path_to_images + img3)\n",
    "#plot the images\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "#size of the plot\n",
    "#the colors are inverted because of the way matplotlib reads the images\n",
    "#invert the colors\n",
    "img1 = np.invert(img1)\n",
    "img2 = np.invert(img2)\n",
    "img3 = np.invert(img3)\n",
    "ax[0].imshow(img1)\n",
    "ax[0].set_title(\"Underarmor1\")\n",
    "ax[1].imshow(img2)\n",
    "ax[1].set_title(\"Underarmor2\")\n",
    "ax[2].imshow(img3)\n",
    "ax[2].set_title(\"Lego\")\n",
    "plt.show()\n",
    "print(\"Similarity score of VGG between Underarmor1 and Underarmor2: 0.77082705\")\n",
    "print (\"Similarity score of VGG Underarmor1 and Lego: 0.47096005\\n\")\n",
    "##Similarity score between img1 and img2:  [[0.77082705]]\n",
    "#Similarity score between img1 and img3:  [[0.47096005]]\n",
    "#plot the similarities\n",
    "\n",
    "description1 = \"These running shoes are built to help anyone go faster-Charged Cushioning helps protect against impact, leather overlays add durable stability, and a mesh upper keeps your feet cool for miles.. Lightweight mesh upper with 3-color digital print delivers complete breathability. Durable leather overlays for stability & that locks in your midfoot. EVA sockliner provides soft, step-in comfort. Charged Cushioning midsole uses compression molded foam for ultimate responsiveness & durability. Solid rubber outsole covers high impact zones for greater durability with less weight. Offset: 10mm. NEUTRAL: For runners who need a balance of flexibility & cushioning. Lace type: Standard tie.\"\n",
    "description2=\"These shoes are going to feel cushioned and comfortable, but also light and breathable. Why? Because when you never slow down, that's what you need. Breathable mesh upper with synthetic overlays for added structure & support. Enhanced cushioning around ankle collar for superior comfort. Deluxe Comfort System sockliner molds to your foot for ultimate step-in comfort. Charged Cushioning midsole provides all day comfort with responsiveness & durability. Durable rubber outsole provides traction & durability with flexibility where you need it for toe-off. Offset: 8mm. Weight: 10.05 oz. Lace type: Standard tie. NEUTRAL: For runners who need a balance of flexibility & cushioning.\"\n",
    "\n",
    "description3=\"Appeal to older kids and Lilo and Stitch fans ages 9 and up with this LEGO Disney Stitch (43249) buildable play and display set, featuring a Stitch toy character. The incorrigible extraterrestrial from the hit Disney movie, dressed in a Hawaiian shirt, has movable ears and a turning head, a buildable ice cream cone that the character can hold and a buildable flower that can be added or removed. This Disney toy for 9 year old kids looks great on display in any room and makes a fun Disney gift idea for older children and movie lovers as they set up the buildable character. Kids and grown-up fans alike will appreciate the details in this building toy that lets them build and play with the iconic character together. Kids also enjoy an easy and intuitive building adventure with the LEGO Builder app, where they can zoom in and rotate models in 3D, save sets and track their progress. Contains 730 pieces.\"\n",
    "#print the descriptions\n",
    "print(\"Description of Underarmor1:\\n \", description1)\n",
    "print(\"Description of Underarmor2: \\n\", description2)\n",
    "print(\"Description of Lego: \\n\", description3,\"\\n\")\n",
    "#print the similarity scores\n",
    "#Similarity score between url1 and url2:  [[0.9773201]]\n",
    "#Similarity score between url1 and url3:  [[0.7952991]]\n",
    "#print the similarity\n",
    "print (\"Similarity score of the descriptions between Underarmor1 and Underarmor2: \",cosine_similarity(text_evaluation.text_embedding(description1), text_evaluation.text_embedding(description2)))\n",
    "print(\"Similarity score of the descriptions between Underarmor1 and Lego: \",cosine_similarity(text_evaluation.text_embedding(description1), text_evaluation.text_embedding(description3)),\"\\n\")\n",
    "#print the jaccard similarity between the descriptions\n",
    "jaccard_similarity = text_evaluation.jaccard_similarity(description1, description2)\n",
    "jaccard_similarity2 = text_evaluation.jaccard_similarity(description1, description3)\n",
    "print(\"Jaccard similarity between Underarmor1 and Underarmor2: \", jaccard_similarity)\n",
    "print(\"Jaccard similarity between Underarmor1 and Lego: \", jaccard_similarity2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1826c9f5eb733212"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Hypothesis Testing - Text and Image Similarity"
   ],
   "id": "282c2334d8a78245"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pick Samples"
   ],
   "id": "eebf9098d8f1691b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:57:04.461038Z",
     "start_time": "2024-07-21T15:57:04.457598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = 10"
   ],
   "id": "1377e74cfd988513",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Read CSV"
   ],
   "id": "c3d6bc88803a1ba3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:58:24.652829Z",
     "start_time": "2024-07-21T15:58:20.756352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = os.getcwd() + \"/Datasets\"\n",
    "all_df = pd.read_csv(path + \"/Amazon-Products.csv\")"
   ],
   "id": "378b5caec6752d68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Get Samples"
   ],
   "id": "4a5b383d5634faf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:58:25.317968Z",
     "start_time": "2024-07-21T15:58:25.283661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = all_df.sample(n=samples)\n",
    "display(df)"
   ],
   "id": "12068a0bb77676dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Similarity"
   ],
   "id": "e269923e622f0cc5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T16:08:07.063264Z",
     "start_time": "2024-07-21T15:58:27.221541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "imported_module = importlib.import_module(\"text_evaluation\")\n",
    "importlib.reload(imported_module)\n",
    "import text_evaluation\n",
    "import numpy as np\n",
    "\n",
    "urls = df[\"link\"].to_list()\n",
    "# text sims as a list of lists\n",
    "text_sims = np.array([[text_evaluation.similarity_score(urls[i], urls[j]).item()  for i in range(samples)] for j in range(samples)])"
   ],
   "id": "af82e2a0a3bfde31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Get Embeddings"
   ],
   "id": "badc7d3bc1e6691"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T16:08:47.162286Z",
     "start_time": "2024-07-21T16:08:16.201105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from imager.image_classifier import embed_image_from_url\n",
    "image_urls = df[\"image\"].to_list()\n",
    "embeddings = [embed_image_from_url(image_urls[i]) for i in range(samples)]"
   ],
   "id": "f2af837ad7502e3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Image Similarity"
   ],
   "id": "203ee4b97e98e74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T16:08:47.213848Z",
     "start_time": "2024-07-21T16:08:47.163267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from imager.vgg.VGG import get_score\n",
    "import numpy as np\n",
    "# image sims as a list of lists\n",
    "image_sims = np.array([[get_score(embeddings[i], embeddings[j]).item() for i in range(samples)] for j in range(samples)])"
   ],
   "id": "ded0483787cb8395",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Similairties Matrix"
   ],
   "id": "f15bb1470103a953"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T16:08:47.637011Z",
     "start_time": "2024-07-21T16:08:47.214800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# add column names to the dataframe\n",
    "text_df = pd.DataFrame(text_sims)\n",
    "image_df = pd.DataFrame(image_sims)\n",
    "# get all the index i s.t i,i = 0 in image_df\n",
    "ind = [i for i in range(samples) if image_df.iloc[i,i] == 0]\n",
    "# remove the rows and columns with index i\n",
    "text_df = text_df.drop(ind)\n",
    "text_df = text_df.drop(columns=ind)\n",
    "image_df = image_df.drop(ind)\n",
    "image_df = image_df.drop(columns=ind)"
   ],
   "id": "46520ab8dd9323d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Heatmap"
   ],
   "id": "e80de18e246630eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T16:08:48.325033Z",
     "start_time": "2024-07-21T16:08:47.638945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sims = pd.DataFrame(image_df)\n",
    "\n",
    "# x * text_sim + 1-x * image_sim\n",
    "\n",
    "avg_val = sims.to_numpy().mean()\n",
    "# Text Similarity heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "mask = np.triu(np.ones_like(sims, dtype=bool))\n",
    "plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(sims, annot=True, mask=mask)\n",
    "sns.heatmap(sims, annot=True, xticklabels=[f\"Prod {i}\" for i in range(len(sims))], yticklabels=[f\"Prod {i}\" for i in range(len(sims))])\n",
    "\n",
    "# add title\n",
    "plt.title(\"Image Similarity Heatmap\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "3b8247a1d172a65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T16:08:48.886255Z",
     "start_time": "2024-07-21T16:08:48.327034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sims = pd.DataFrame(text_df)\n",
    "\n",
    "# x * text_sim + 1-x * image_sim\n",
    "\n",
    "avg_val = sims.to_numpy().mean()\n",
    "# Text Similarity heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "mask = np.triu(np.ones_like(sims, dtype=bool))\n",
    "plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(sims, annot=True, mask=mask)\n",
    "sns.heatmap(sims, annot=True, xticklabels=[f\"Prod {i}\" for i in range(len(sims))], yticklabels=[f\"Prod {i}\" for i in range(len(sims))])\n",
    "\n",
    "# add title\n",
    "plt.title(\"Text Similarity Heatmap\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "c91f84361e5d0485",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T16:08:55.202740Z",
     "start_time": "2024-07-21T16:08:52.587820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make the heatmaps of the text and image similarities, and the difference between them as subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(30, 8))\n",
    "# Text Similarity heatmap\n",
    "sns.heatmap(text_df, annot=True, ax=axs[0], xticklabels=[f\"Prod {i}\" for i in range(len(sims))], yticklabels=[f\"Prod {i}\" for i in range(len(sims))])\n",
    "axs[0].set_title(\"Text Similarity\", fontsize=20)\n",
    "# Image Similarity heatmap\n",
    "sns.heatmap(image_df, annot=True, ax=axs[1], xticklabels=[f\"Prod {i}\" for i in range(len(sims))], yticklabels=[f\"Prod {i}\" for i in range(len(sims))])\n",
    "axs[1].set_title(\"Image Similarity\", fontsize=20)\n",
    "# Difference heatmap\n",
    "sns.heatmap(text_df / image_df, annot=True, ax=axs[2], xticklabels=[f\"Prod {i}\" for i in range(len(sims))], yticklabels=[f\"Prod {i}\" for i in range(len(sims))])\n",
    "axs[2].set_title(\"Difference (Text / Image)\", fontsize=20)\n",
    "# add title\n",
    "plt.suptitle(\"Text/Image Similarity Heatmaps\", fontsize=30)\n",
    "plt.show()"
   ],
   "id": "f1bc6a82720f143f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:11:03.237351Z",
     "start_time": "2024-07-21T15:11:02.860351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sims = pd.DataFrame(np.abs(text_df / image_df))\n",
    "\n",
    "# x * text_sim + 1-x * image_sim\n",
    "\n",
    "avg_val = sims.to_numpy().mean()\n",
    "# Text Similarity heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "mask = np.triu(np.ones_like(sims, dtype=bool))\n",
    "plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(sims, annot=True, mask=mask)\n",
    "sns.heatmap(sims, annot=True, xticklabels=[f\"Prod {i}\" for i in range(len(sims))], yticklabels=[f\"Prod {i}\" for i in range(len(sims))])\n",
    "\n",
    "# add title\n",
    "plt.title(\"Text/Image Similarity Heatmap\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "2a496da39031555",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Heatmap with average value"
   ],
   "id": "22dd5985fe1b9412"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T14:51:46.289025Z",
     "start_time": "2024-07-21T14:51:45.134027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_df2 = image_df * avg_val\n",
    "sims2 = pd.DataFrame(np.abs(text_df - image_df2))\n",
    "# mask = np.triu(np.ones_like(sims2, dtype=bool))\n",
    "plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(sims2, annot=True, mask=mask)\n",
    "sns.heatmap(sims2, annot=True)\n",
    "plt.show()"
   ],
   "id": "87eecf004bf407",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Exploration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1310d81c0ce2294e"
  },
  {
   "cell_type": "code",
   "source": [
    "x = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-21T11:10:53.995648Z",
     "start_time": "2024-07-21T11:08:27.029098Z"
    }
   },
   "id": "c1b693c3b49111e3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
