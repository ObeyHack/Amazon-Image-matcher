{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Requirements"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "138421a6c861b324"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-05T14:42:44.304545Z",
     "start_time": "2024-07-05T14:42:31.671546Z"
    }
   },
   "source": [
    "import os\n",
    "import hickle as hkl\n",
    "import requests\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "from VGG import get_image_embeddings, load_image_bytes, load_image, get_score, label"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading the csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85667c113c65faf3"
  },
  {
   "cell_type": "code",
   "source": [
    "tqdm.pandas()\n",
    "path = os.getcwd() + \"/Datasets\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "csv_dfs = {}\n",
    "for f in csv_files:\n",
    "    file_name = f.split(\"\\\\\")[-1]\n",
    "    \n",
    "    # remove the .csv extension\n",
    "    file_name = file_name[:-4]\n",
    "    \n",
    "    if file_name == \"Amazon-Products\":\n",
    "        continue\n",
    "    \n",
    "    # read the csv file \n",
    "    df = pd.read_csv(f)\n",
    "    csv_dfs[file_name] = df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T14:42:50.992544Z",
     "start_time": "2024-07-05T14:42:46.364546Z"
    }
   },
   "id": "96dc3716b614b816",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Saving the images embedding\n",
    "\n",
    "we take the entire dataset Amazon-Products.csv and save the numpy vectors embeddings of the images in the dataset to a gzip file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "295464ec00cf59c1"
  },
  {
   "cell_type": "code",
   "source": [
    "# download image\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    img_data = response.content\n",
    "    return img_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T14:42:55.612574Z",
     "start_time": "2024-07-05T14:42:55.595569Z"
    }
   },
   "id": "f6bb9c1ee0748c9c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "def embed_image_from_url(url):\n",
    "    img_data = download_image(url)\n",
    "    if img_data is None:\n",
    "        return np.zeros((1, 512))\n",
    "    img = load_image_bytes(img_data)\n",
    "    embedding = get_image_embeddings(img)\n",
    "    return embedding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T14:42:56.971580Z",
     "start_time": "2024-07-05T14:42:56.954547Z"
    }
   },
   "id": "148728665ee800b4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.exists(\"images\"):\n",
    "    os.mkdir(\"images/\")\n",
    "\n",
    "# .keep file to keep the directory in git\n",
    "with open(\"images/.keep\", 'w') as f:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T14:42:58.329546Z",
     "start_time": "2024-07-05T14:42:58.313547Z"
    }
   },
   "id": "7d1c485fe79236f1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "with h5py.File(\"images/dataset.hdf5\", \"a\") as f:\n",
    "    for file in csv_dfs:\n",
    "        print(\"Processing\", file)\n",
    "        if file in f:\n",
    "            continue\n",
    "            \n",
    "        urls = csv_dfs[file][\"image\"]\n",
    "        \n",
    "        # apply embed_image_from_url to all the urls and create a pd.Series with the embeddings\n",
    "        embeddings = urls.progress_apply(embed_image_from_url)\n",
    "        # create a dataset for each file in a specific group\n",
    "        grp = f.create_group(file)\n",
    "        dataset = grp.create_dataset(\"images\", (len(urls), 1, embeddings[0].shape[1]), data=embeddings.to_list(),\n",
    "                                     shuffle=True, dtype='f', compression=\"gzip\", compression_opts=9)    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T14:43:01.228545Z",
     "start_time": "2024-07-05T14:42:59.562545Z"
    }
   },
   "id": "655f66e9bcce6945",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Air Conditioners\n",
      "Processing All Appliances\n",
      "Processing All Books\n",
      "Processing All Car and Motorbike Products\n",
      "Processing All Electronics\n",
      "Processing All English\n",
      "Processing All Exercise and Fitness\n",
      "Processing All Grocery and Gourmet Foods\n",
      "Processing All Hindi\n",
      "Processing All Home and Kitchen\n",
      "Processing All Movies and TV Shows\n",
      "Processing All Music\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1be341c723f94822ae040b37d7326581"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32m~\\Desktop\\Uni\\Year3\\SemB\\Data\\MainProject\\Amazon-Image-matcher\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:413\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    412\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 413\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_range\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[1;31mValueError\u001B[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# create a dataset for each file in a specific group\u001B[39;00m\n\u001B[0;32m     12\u001B[0m grp \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mcreate_group(file)\n\u001B[1;32m---> 13\u001B[0m dataset \u001B[38;5;241m=\u001B[39m grp\u001B[38;5;241m.\u001B[39mcreate_dataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m, (\u001B[38;5;28mlen\u001B[39m(urls), \u001B[38;5;241m1\u001B[39m, \u001B[43membeddings\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]), data\u001B[38;5;241m=\u001B[39membeddings\u001B[38;5;241m.\u001B[39mto_list(),\n\u001B[0;32m     14\u001B[0m                              shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m, compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgzip\u001B[39m\u001B[38;5;124m\"\u001B[39m, compression_opts\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m9\u001B[39m)    \n",
      "File \u001B[1;32m~\\Desktop\\Uni\\Year3\\SemB\\Data\\MainProject\\Amazon-Image-matcher\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1121\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[0;32m   1120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[1;32m-> 1121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1123\u001B[0m \u001B[38;5;66;03m# Convert generator to list before going through hashable part\u001B[39;00m\n\u001B[0;32m   1124\u001B[0m \u001B[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001B[39;00m\n\u001B[0;32m   1125\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n",
      "File \u001B[1;32m~\\Desktop\\Uni\\Year3\\SemB\\Data\\MainProject\\Amazon-Image-matcher\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1237\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[1;34m(self, label, takeable)\u001B[0m\n\u001B[0;32m   1234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[0;32m   1236\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[1;32m-> 1237\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(loc):\n\u001B[0;32m   1240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[loc]\n",
      "File \u001B[1;32m~\\Desktop\\Uni\\Year3\\SemB\\Data\\MainProject\\Amazon-Image-matcher\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:415\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    413\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_range\u001B[38;5;241m.\u001B[39mindex(new_key)\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m--> 415\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m    416\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Hashable):\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Usage"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d390210e81c630f3"
  },
  {
   "cell_type": "code",
   "source": [
    "with (h5py.File(\"images/dataset.hdf5\", \"r\") as f):\n",
    "    print(f.keys())\n",
    "    emb = f[\"Air Conditioners\"][\"images\"][0]\n",
    "    emb2 = embed_image_from_url(csv_dfs[\"Air Conditioners\"][\"image\"][0])\n",
    "    print(emb.shape)\n",
    "    print(emb == emb2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T08:36:13.048477Z",
     "start_time": "2024-06-30T08:36:12.442755Z"
    }
   },
   "id": "873d5b7eeb32b6d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['Air Conditioners', 'All Appliances', 'All Books', 'All Car and Motorbike Products', 'All Electronics', 'All English', 'All Exercise and Fitness', 'All Grocery and Gourmet Foods', 'All Hindi', 'All Home and Kitchen', 'All Movies and TV Shows']>\n",
      "(1, 512)\n",
      "[[False False  True  True False False False  True  True False  True  True\n",
      "  False  True False False  True False False False  True False False  True\n",
      "   True False False False False False False  True False  True  True False\n",
      "   True False  True False False False False  True False False False False\n",
      "  False False False False False False False False  True False False False\n",
      "  False  True False  True False  True False False False  True  True False\n",
      "  False False False False  True False  True  True  True False False  True\n",
      "   True  True False  True  True False False  True False  True False False\n",
      "   True False False False  True False False  True False  True False False\n",
      "  False False  True  True  True False  True False  True False  True False\n",
      "  False False  True False False False  True  True  True False False False\n",
      "  False  True False  True  True False False  True False  True False  True\n",
      "  False  True False False False False False  True False False  True False\n",
      "  False  True  True False False  True False False False False  True  True\n",
      "  False  True  True  True False False False False False False False False\n",
      "  False False False  True False  True False False  True  True False  True\n",
      "  False False False  True False False  True False  True False  True False\n",
      "   True False False False  True False False False  True False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False  True  True False False  True  True\n",
      "  False  True  True False False  True False False False False False  True\n",
      "  False False False False False False False False  True False  True  True\n",
      "  False  True False False  True  True False False False  True False  True\n",
      "  False  True  True False False  True False False  True  True  True  True\n",
      "   True  True False  True False False False  True False False False False\n",
      "   True  True False  True False False False False  True False  True  True\n",
      "  False  True False False False False  True False False False False False\n",
      "  False  True False  True False  True  True False False False False False\n",
      "   True False  True  True False False False False False  True False False\n",
      "   True  True False False False False False False False False False False\n",
      "   True False False False False  True False False False False  True  True\n",
      "  False  True False False  True False  True False False False False  True\n",
      "  False False False False False  True False False False  True False False\n",
      "  False  True False  True  True False False False False False False False\n",
      "   True False  True  True  True False  True  True False False  True False\n",
      "  False  True False False  True False  True  True False  True False False\n",
      "   True False False False  True  True False False False False False False\n",
      "  False  True  True False False False False  True False  True False False\n",
      "  False  True False False False False False False  True False False False\n",
      "  False False False False  True False False  True False  True False False\n",
      "  False False False False False  True False False False  True  True False\n",
      "  False False False False False False False False  True  True False False\n",
      "  False False  True False False  True False  True]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Multi-threading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84a4ad4f3b22b3b5"
  },
  {
   "cell_type": "code",
   "source": [
    "urls = {file: csv_dfs[file][\"image\"] for file in csv_dfs}\n",
    "\n",
    "# only values 2 keys\n",
    "urls = {k: urls[k] for k in list(urls)[-48:-32]}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T14:43:53.244570Z",
     "start_time": "2024-07-05T14:43:53.229569Z"
    }
   },
   "id": "9e158e66eb4e7d7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "def download_csv_images(file, img_urls):\n",
    "    # check if \"images\" not in f:\n",
    "    if os.path.exists(f\"images/{file}.hdf5\"):\n",
    "        with h5py.File(f\"images/{file}.hdf5\", \"r\") as f:\n",
    "            if \"images\" in f:\n",
    "                return\n",
    "        \n",
    "    # add \n",
    "    tqdm.pandas(desc=f\"{file}\", postfix=None)\n",
    "    embeddings = img_urls.progress_apply(embed_image_from_url)\n",
    "    with h5py.File(f\"images/{file}.hdf5\", \"a\") as f:\n",
    "        f.create_dataset(\"images\", (len(img_urls), 1, embeddings[0].shape[1]), data=embeddings.to_list(),\n",
    "                                         shuffle=True, dtype='f', compression=\"gzip\", compression_opts=9)\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T14:43:55.372543Z",
     "start_time": "2024-07-05T14:43:55.359544Z"
    }
   },
   "id": "6bd47a13256afe16",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "    for file in urls:\n",
    "        executor.submit(download_csv_images, file, urls[file])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-07-05T16:58:17.720036Z",
     "start_time": "2024-07-05T14:43:58.181333Z"
    }
   },
   "id": "4592b7f78ea42248",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lingerie and Nightwear:   0%|          | 0/19104 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c13e1e6019d349569a5e01ca05286c5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Make-up:   0%|          | 0/2640 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f29c1441ce84951850eac907f331870"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Luxury Beauty:   0%|          | 0/864 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5d629032d9f4a4fa311ace300689206"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Mens Fashion:   0%|          | 0/19200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f552a67a3c03402baf17770d3dfddd5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Motorbike Accessories and Parts:   0%|          | 0/1224 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2dc6fe3ecca74d4da3f4804ea78c35f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Nursing and Feeding:   0%|          | 0/1056 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "363ebd3129cb4cc4baf21393b555554d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Musical Instruments and Professional Audio:   0%|          | 0/1080 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfbd0da360e74d099570e2f917607475"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Personal Care Appliances:   0%|          | 0/1224 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "919c2f8963d04a629c7f2ae4f914c9bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PC Games: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a55fd1c5b8049c9adc0ea18ef558208"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Refurbished and Open Box:   0%|          | 0/24 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "824cfea8a2f84087bb98f4b8463065f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Rucksacks:   0%|          | 0/2208 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4286e7b1238e44c5b031445ce0d32c8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pantry: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19e17c12ea6d470e888bebc7d34afe2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Refrigerators:   0%|          | 0/2160 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a05afc601abd4499b43c6999bf1d6513"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "School Bags:   0%|          | 0/2352 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d945137fbbd4701b0e0d73bb13452f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "School Textbooks: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "696aff13cfcf41ab89166cf819d10e6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Running:   0%|          | 0/912 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0922f475bfa5499389829a4079eba33f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001EB038739A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001EB038739A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Testing the embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c11f281d70b11d81"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def argmax_score(input_embedding, embeddings):\n",
    "    return np.argmax([get_score(input_embedding, emb) for emb in embeddings])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T21:05:03.261867300Z",
     "start_time": "2024-06-29T21:05:03.223885500Z"
    }
   },
   "id": "184000caffaacb1c",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def argmax_csv(input_embedding, csv_dfs):\n",
    "    csv_scores = {}\n",
    "    for file in tqdm(csv_dfs):\n",
    "        if not os.path.exists(f\"images/{file}.hdf5\"):\n",
    "            continue\n",
    "        \n",
    "        with h5py.File(f\"images/{file}.hdf5\", \"r\") as f:\n",
    "            if \"images\" in f:\n",
    "                csv_embeddings = f[\"images\"]\n",
    "                csv_scores[file] = argmax_score(input_embedding, csv_embeddings)\n",
    "    return csv_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T21:09:43.949938900Z",
     "start_time": "2024-06-29T21:09:43.921407900Z"
    }
   },
   "id": "8c2c38e54365569",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/139 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c75624812674f54bf672f30f74dd80c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Fashion 1861\n"
     ]
    },
    {
     "data": {
      "text/plain": "name              PMW - Hair Accessories - Hair Bun - Bharatanat...\nmain_category                                                stores\nsub_category                                         Amazon Fashion\nimage             https://m.media-amazon.com/images/I/61yBpKUuV9...\nlink              https://www.amazon.in/PMW-Accessories-Bharatan...\nratings                                                         4.4\nno_of_ratings                                                     9\ndiscount_price                                                 ₹229\nactual_price                                                   ₹599\nName: 1861, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_img_path = \"sunflower/sunflower1.jpg\"\n",
    "input_img = load_image(input_img_path)\n",
    "input_embedding = get_image_embeddings(input_img)\n",
    "\n",
    "csv_scores = argmax_csv(input_embedding, csv_dfs)\n",
    "max_csv = max(csv_scores, key=csv_scores.get)\n",
    "max_row = max(csv_scores.values())\n",
    "print(max_csv, max_row)\n",
    "\n",
    "\n",
    "display(csv_dfs[max_csv].iloc[max_row])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-29T21:10:01.123964900Z",
     "start_time": "2024-06-29T21:09:44.807280700Z"
    }
   },
   "id": "c0ab568e46d5fef7",
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
